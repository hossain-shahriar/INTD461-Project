{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a20c063",
   "metadata": {},
   "source": [
    "## Setup: device, imports, paths, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55b37b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA H100 80GB HBM3 MIG 2g.20gb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6029407/mhossai6/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK WordNet data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/mhossai6/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/mhossai6/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_WSD = True\n",
      "BATCH_GEN = 32\n"
     ]
    }
   ],
   "source": [
    "# 01 - Setup: device, imports, paths, config\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "# ---- Device ----\n",
    "RUN_DEVICE = \"gpu\"  # \"gpu\" or \"cpu\"\n",
    "\n",
    "if RUN_DEVICE.lower() == \"gpu\" and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# ---- Seeds ----\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# ---- Transformers ----\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# ---- WSD: NLTK WordNet (custom simple Lesk) ----\n",
    "import nltk\n",
    "\n",
    "# Make sure WordNet + stopwords are available\n",
    "try:\n",
    "    nltk.data.find(\"corpora/wordnet\")\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK WordNet data...\")\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"omw-1.4\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK stopwords data...\")\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "# ---- Paths ----\n",
    "DATA_DIR = Path(\"SemEval_2022_Task2-idiomaticity/SubTaskA\")\n",
    "TRAIN_ONE_SHOT = DATA_DIR / \"Data\" / \"train_one_shot.csv\"\n",
    "TRAIN_ZERO_SHOT = DATA_DIR / \"Data\" / \"train_zero_shot.csv\"\n",
    "DEV = DATA_DIR / \"Data\" / \"dev.csv\"\n",
    "DEV_GOLD = DATA_DIR / \"Data\" / \"dev_gold.csv\"\n",
    "EVAL = DATA_DIR / \"Data\" / \"eval.csv\"\n",
    "\n",
    "OUT_DIR = Path(\"outputs_en_llm_wsd\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- LLM config ----\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"  # adjust if you want a smaller one\n",
    "\n",
    "# Larger batch if GPU\n",
    "BATCH_GEN = 8 if device.type == \"cpu\" else 32\n",
    "\n",
    "# Toggle WSD usage\n",
    "USE_WSD = True\n",
    "print(\"USE_WSD =\", USE_WSD)\n",
    "print(\"BATCH_GEN =\", BATCH_GEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35bb60",
   "metadata": {},
   "source": [
    "## Data loading, context utils, WSD helpers, EN loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46bea39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 - Data loading, context, WSD, EN train/dev/eval helpers\n",
    "\n",
    "def load_any_csv(path: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(path, sep=None, engine=\"python\", dtype=str)\n",
    "\n",
    "def ensure_label_int(df: pd.DataFrame, col=\"Label\") -> pd.DataFrame:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    return df\n",
    "\n",
    "def mark_first_case_insensitive(text: str, needle: str, ltag=\"<mwe>\", rtag=\"</mwe>\") -> str:\n",
    "    if not isinstance(text, str) or not isinstance(needle, str):\n",
    "        return text\n",
    "    lt = text.lower()\n",
    "    ln = needle.lower()\n",
    "    i = lt.find(ln)\n",
    "    if i == -1:\n",
    "        return text\n",
    "    return text[:i] + ltag + text[i:i+len(needle)] + rtag + text[i+len(needle):]\n",
    "\n",
    "def pack_context(prev: str, target: str, nxt: str, mwe: str) -> str:\n",
    "    prev = \"\" if pd.isna(prev) else prev\n",
    "    nxt = \"\" if pd.isna(nxt) else nxt\n",
    "    target = \"\" if pd.isna(target) else target\n",
    "    tgt_marked = mark_first_case_insensitive(target, mwe)\n",
    "    return f\"Previous: {prev}\\nTarget: {tgt_marked}\\nNext: {nxt}\"\n",
    "\n",
    "# ---- WSD helpers (custom simple Lesk using NLTK WordNet) ----\n",
    "\n",
    "def build_simple_sentence(row) -> str:\n",
    "    prev = row.get(\"Previous\", \"\")\n",
    "    tgt = row.get(\"Target\", \"\")\n",
    "    nxt = row.get(\"Next\", \"\")\n",
    "\n",
    "    def _clean(x):\n",
    "        if isinstance(x, str):\n",
    "            return x\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "        return str(x)\n",
    "\n",
    "    prev = _clean(prev)\n",
    "    tgt = _clean(tgt)\n",
    "    nxt = _clean(nxt)\n",
    "    return \" \".join([prev, tgt, nxt]).strip()\n",
    "\n",
    "\n",
    "def get_mwe_head(mwe: str) -> str:\n",
    "    if not isinstance(mwe, str):\n",
    "        return \"\"\n",
    "    toks = mwe.split()\n",
    "    return toks[-1] if toks else \"\"\n",
    "\n",
    "\n",
    "def simple_lesk_nltk(context_sentence: str, ambiguous_word: str):\n",
    "    \"\"\"\n",
    "    Very small Lesk-style WSD using NLTK WordNet.\n",
    "    Returns a Synset or None.\n",
    "    \"\"\"\n",
    "    if not context_sentence or not ambiguous_word:\n",
    "        return None\n",
    "\n",
    "    tokens = [\n",
    "        w.strip(string.punctuation).lower()\n",
    "        for w in context_sentence.split()\n",
    "    ]\n",
    "    context = [w for w in tokens if w and w not in STOP_WORDS]\n",
    "\n",
    "    synsets = wn.synsets(ambiguous_word)\n",
    "    if not synsets:\n",
    "        return None\n",
    "\n",
    "    best_syn = None\n",
    "    max_overlap = 0\n",
    "\n",
    "    for syn in synsets:\n",
    "        sig_tokens = syn.definition().split()\n",
    "        for ex in syn.examples():\n",
    "            sig_tokens += ex.split()\n",
    "\n",
    "        sig_tokens = [\n",
    "            w.strip(string.punctuation).lower()\n",
    "            for w in sig_tokens\n",
    "        ]\n",
    "        signature = [w for w in sig_tokens if w and w not in STOP_WORDS]\n",
    "\n",
    "        overlap = len(set(signature) & set(context))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_syn = syn\n",
    "\n",
    "    return best_syn\n",
    "\n",
    "\n",
    "def annotate_with_wsd(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds SenseID and SenseGloss columns for EN rows using simple_lesk_nltk.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    sense_ids = []\n",
    "    sense_glosses = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sent = build_simple_sentence(row)\n",
    "        mwe = row.get(\"MWE\", \"\") or \"\"\n",
    "        head = get_mwe_head(mwe)\n",
    "\n",
    "        if not sent or not head:\n",
    "            sense_ids.append(\"\")\n",
    "            sense_glosses.append(\"\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            synset = simple_lesk_nltk(sent, head)\n",
    "        except Exception:\n",
    "            synset = None\n",
    "\n",
    "        if synset is None:\n",
    "            sense_ids.append(\"\")\n",
    "            sense_glosses.append(\"\")\n",
    "        else:\n",
    "            sense_ids.append(synset.name())\n",
    "            sense_glosses.append(synset.definition())\n",
    "\n",
    "    df[\"SenseID\"] = sense_ids\n",
    "    df[\"SenseGloss\"] = sense_glosses\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_train_dev(language=\"EN\", oneshot=True) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if oneshot:\n",
    "        train_df = load_any_csv(TRAIN_ONE_SHOT)\n",
    "    else:\n",
    "        train_df = load_any_csv(TRAIN_ZERO_SHOT)\n",
    "    dev_df = load_any_csv(DEV)\n",
    "    gold_df = load_any_csv(DEV_GOLD)\n",
    "\n",
    "    train_df.columns = [c.strip() for c in train_df.columns]\n",
    "    dev_df.columns = [c.strip() for c in dev_df.columns]\n",
    "    gold_df.columns = [c.strip() for c in gold_df.columns]\n",
    "\n",
    "    train_df = train_df[train_df[\"Language\"] == language].copy()\n",
    "    dev_df = dev_df[dev_df[\"Language\"] == language].copy()\n",
    "\n",
    "    gold = gold_df[gold_df[\"Language\"] == language][[\"ID\", \"Label\"]].copy()\n",
    "    gold[\"ID\"] = gold[\"ID\"].astype(str)\n",
    "    dev_df[\"ID\"] = dev_df[\"ID\"].astype(str)\n",
    "    dev_lab = dev_df.merge(gold, on=\"ID\", how=\"left\")\n",
    "\n",
    "    train_df = ensure_label_int(train_df, \"Label\")\n",
    "    dev_lab = ensure_label_int(dev_lab, \"Label\")\n",
    "\n",
    "    if USE_WSD:\n",
    "        print(f\"Annotating train/dev ({language}, oneshot={oneshot}) with WSD...\")\n",
    "        train_df = annotate_with_wsd(train_df)\n",
    "        dev_lab = annotate_with_wsd(dev_lab)\n",
    "\n",
    "    return train_df, dev_lab\n",
    "\n",
    "\n",
    "def load_eval(language=\"EN\") -> pd.DataFrame:\n",
    "    df = load_any_csv(EVAL)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df = df[df[\"Language\"] == language].copy()\n",
    "\n",
    "    if USE_WSD:\n",
    "        print(f\"Annotating eval ({language}) with WSD...\")\n",
    "        df = annotate_with_wsd(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c64df8",
   "metadata": {},
   "source": [
    "## Load Qwen model & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e7487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "2025-11-26 23:44:23.609503: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-26 23:44:23.623598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764229463.633895  503544 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764229463.636564  503544 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764229463.645714  503544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764229463.645724  503544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764229463.645726  503544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764229463.645728  503544 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-26 23:44:23.649301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LLM: Qwen/Qwen2.5-7B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# 03 - Load Qwen model & tokenizer\n",
    "\n",
    "# If you need HF login, you can uncomment this and set HF_TOKEN env var.\n",
    "# from huggingface_hub import login as hf_login\n",
    "# HF_TOKEN = os.getenv(\"HF_TOKEN\", \"\").strip()\n",
    "# if HF_TOKEN:\n",
    "#     hf_login(token=HF_TOKEN)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    use_fast=True,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=torch.float32,\n",
    "        device_map={\"\": \"cpu\"},\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    if tokenizer.eos_token_id is not None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    else:\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model.eval()\n",
    "print(\"Loaded LLM:\", MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eadda8",
   "metadata": {},
   "source": [
    "## Chat/plain encoding & logits-based 0/1 classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730c0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04 - Helpers: chat/plain encoding & logits-based 0/1 classification\n",
    "\n",
    "def _apply_chat_or_plain_batch(texts: list, max_len: int = 512) -> dict:\n",
    "    \"\"\"\n",
    "    Tokenize a batch of prompts, with an explicit max_len to avoid huge sequences.\n",
    "    \"\"\"\n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        messages_batch = [[\n",
    "            {\"role\": \"system\", \"content\": \"You are a concise classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": t}\n",
    "        ] for t in texts]\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            messages_batch,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_len,  # <<< important\n",
    "        )\n",
    "    else:\n",
    "        input_ids = tokenizer(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_len,  # <<< important\n",
    "        ).input_ids\n",
    "\n",
    "    attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
    "    return {\n",
    "        \"input_ids\": input_ids.to(device),\n",
    "        \"attention_mask\": attention_mask.to(device),\n",
    "    }\n",
    "\n",
    "\n",
    "_id0 = None\n",
    "_id1 = None\n",
    "\n",
    "def _candidate_token_id_for_digit(d: str) -> Optional[int]:\n",
    "    ids = tokenizer.encode(d, add_special_tokens=False)\n",
    "    if len(ids) == 1:\n",
    "        return ids[0]\n",
    "    ids = tokenizer.encode(\" \" + d, add_special_tokens=False)\n",
    "    if len(ids) == 1:\n",
    "        return ids[0]\n",
    "    ids = tokenizer.encode(d + \"\\n\", add_special_tokens=False)\n",
    "    if len(ids) == 1:\n",
    "        return ids[0]\n",
    "    return None\n",
    "\n",
    "def _init_digit_ids():\n",
    "    global _id0, _id1\n",
    "    if _id0 is None:\n",
    "        _id0 = _candidate_token_id_for_digit(\"0\")\n",
    "    if _id1 is None:\n",
    "        _id1 = _candidate_token_id_for_digit(\"1\")\n",
    "\n",
    "_init_digit_ids()\n",
    "\n",
    "def classify_prompts_logits(prompts: list) -> list:\n",
    "    \"\"\"\n",
    "    Returns list of 0/1 predictions using next-token logits; falls back to\n",
    "    generate-and-parse if 0/1 token IDs are not found.\n",
    "    \"\"\"\n",
    "    # if you want you can pass a smaller max_len here, e.g. 384\n",
    "    enc = _apply_chat_or_plain_batch(prompts, max_len=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits  # [B, T, V]\n",
    "        next_logits = logits[:, -1, :]\n",
    "        if _id0 is not None and _id1 is not None:\n",
    "            logit0 = next_logits[:, _id0]\n",
    "            logit1 = next_logits[:, _id1]\n",
    "            return (logit1 >= logit0).long().detach().cpu().tolist()\n",
    "\n",
    "    # Fallback: generate one token, parse 0/1 from text\n",
    "    outs = []\n",
    "    with torch.no_grad():\n",
    "        gen = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=1,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    for i in range(gen.size(0)):\n",
    "        cut = enc[\"input_ids\"][i].shape[-1]\n",
    "        new_ids = gen[i][cut:]\n",
    "        text = tokenizer.decode(new_ids, skip_special_tokens=True)\n",
    "        if \"0\" in text and \"1\" in text:\n",
    "            outs.append(1 if text.index(\"1\") < text.index(\"0\") else 0)\n",
    "        elif \"1\" in text:\n",
    "            outs.append(1)\n",
    "        elif \"0\" in text:\n",
    "            outs.append(0)\n",
    "        else:\n",
    "            outs.append(1)  # default bias towards idiomatic\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0260bb",
   "metadata": {},
   "source": [
    "## Zero-shot EN with optional WSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a937e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating train/dev (EN, oneshot=False) with WSD...\n",
      "Zero-shot EN (dev, USE_WSD=True) | Resuming with 466 cached / 466 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot EN (dev, USE_WSD=True): 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot EN (dev, USE_WSD=True) | Newly computed: 0 | Cached at start: 466 | Total: 466 | Elapsed: 0.0s | 0.001s/example (new only)\n",
      "[LLM Zero-shot EN] Dev macro-F1: 0.4145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3548    0.6044    0.4472       182\n",
      "           1     0.5385    0.2958    0.3818       284\n",
      "\n",
      "    accuracy                         0.4163       466\n",
      "   macro avg     0.4467    0.4501    0.4145       466\n",
      "weighted avg     0.4667    0.4163    0.4073       466\n",
      "\n",
      "[[110  72]\n",
      " [200  84]]\n",
      "Annotating eval (EN) with WSD...\n",
      "Zero-shot EN (eval, USE_WSD=True) | Resuming with 483 cached / 483 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot EN (eval, USE_WSD=True): 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot EN (eval, USE_WSD=True) | Newly computed: 0 | Cached at start: 483 | Total: 483 | Elapsed: 0.0s | 0.001s/example (new only)\n",
      "Wrote outputs_en_llm_wsd/eval_submission_en_llm_zeroshot_wsd.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 05 - Zero-shot EN with optional WSD\n",
    "\n",
    "from time import perf_counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def make_zero_shot_prompt(mwe: str, ctx: str) -> str:\n",
    "    return f\"\"\"You are a classifier that decides whether a multiword expression (MWE) is used literally (0) or idiomatically (1).\n",
    "\n",
    "MWE: {mwe}\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\n",
    "Answer with a single digit: 0 for literal, 1 for idiomatic.\"\"\"\n",
    "\n",
    "def make_zero_shot_prompt_wsd(mwe: str, ctx: str, sense_gloss: str) -> str:\n",
    "    sense_gloss = (sense_gloss or \"\").strip()\n",
    "    extra = \"\"\n",
    "    if sense_gloss:\n",
    "        extra = f\"\"\"\\nWe also have a WordNet sense definition for this expression in this context:\n",
    "\"{sense_gloss}\".\"\"\"\n",
    "    return f\"\"\"You are a classifier that decides whether a multiword expression (MWE) is used literally (0) or idiomatically (1).\n",
    "\n",
    "MWE: {mwe}{extra}\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\n",
    "Answer with a single digit: 0 for literal, 1 for idiomatic.\"\"\"\n",
    "\n",
    "def _load_cache(cache_path: Path) -> dict:\n",
    "    if cache_path.exists():\n",
    "        df = pd.read_csv(cache_path, dtype={\"ID\": str, \"Label\": int})\n",
    "        return dict(zip(df[\"ID\"].astype(str), df[\"Label\"].astype(int)))\n",
    "    return {}\n",
    "\n",
    "def _append_one(cache_path: Path, rec: tuple):\n",
    "    _id, _lab = rec\n",
    "    header_needed = not cache_path.exists()\n",
    "    with open(cache_path, \"a\") as f:\n",
    "        if header_needed:\n",
    "            f.write(\"ID,Label\\n\")\n",
    "        f.write(f\"{_id},{int(_lab)}\\n\")\n",
    "\n",
    "def progressive_predict_zero_shot_batched(df: pd.DataFrame, cache_path: Path, desc: str = \"Zero-shot EN\") -> list:\n",
    "    df = df.copy()\n",
    "    df[\"ID\"] = df[\"ID\"].astype(str)\n",
    "\n",
    "    preds_map = _load_cache(cache_path)\n",
    "    done = set(preds_map.keys())\n",
    "    todo_idx = [i for i, _id in enumerate(df[\"ID\"]) if _id not in done]\n",
    "\n",
    "    print(f\"{desc} | Resuming with {len(done)} cached / {len(df)} total\")\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    for start in tqdm(range(0, len(todo_idx), BATCH_GEN), desc=desc, leave=True):\n",
    "        batch_rows = todo_idx[start:start+BATCH_GEN]\n",
    "        prompts, ids = [], []\n",
    "        for j in batch_rows:\n",
    "            r = df.iloc[j]\n",
    "            _id = r[\"ID\"]\n",
    "            mwe = r[\"MWE\"]\n",
    "            ctx = pack_context(r.get(\"Previous\",\"\"), r.get(\"Target\",\"\"), r.get(\"Next\",\"\"), mwe)\n",
    "            if USE_WSD:\n",
    "                gloss = (r.get(\"SenseGloss\", \"\") or \"\").strip()\n",
    "                prompt = make_zero_shot_prompt_wsd(mwe, ctx, gloss)\n",
    "            else:\n",
    "                prompt = make_zero_shot_prompt(mwe, ctx)\n",
    "            prompts.append(prompt)\n",
    "            ids.append(_id)\n",
    "        if not prompts:\n",
    "            continue\n",
    "        labels = classify_prompts_logits(prompts)\n",
    "        for _id, lab in zip(ids, labels):\n",
    "            preds_map[_id] = int(lab)\n",
    "            _append_one(cache_path, (_id, int(lab)))\n",
    "\n",
    "    elapsed = perf_counter() - t0\n",
    "    print(f\"{desc} | Newly computed: {len(todo_idx)} | Cached at start: {len(done)} | Total: {len(df)} | \"\n",
    "          f\"Elapsed: {elapsed:.1f}s | {(elapsed/max(1,len(todo_idx))):.3f}s/example (new only)\")\n",
    "\n",
    "    yhat = [preds_map[str(i)] for i in df[\"ID\"]]\n",
    "    return yhat\n",
    "\n",
    "# ---- Run zero-shot EN (dev + eval) ----\n",
    "\n",
    "train_0s_en, dev_0s_en = load_train_dev(language=\"EN\", oneshot=False)\n",
    "\n",
    "cache_dev_0s = OUT_DIR / f\"cache_llm_zeroshot_dev_en_{'wsd' if USE_WSD else 'baseline'}.csv\"\n",
    "yhat_dev_0s = progressive_predict_zero_shot_batched(dev_0s_en, cache_dev_0s, desc=f\"Zero-shot EN (dev, USE_WSD={USE_WSD})\")\n",
    "ytrue_dev_0s = dev_0s_en[\"Label\"].tolist()\n",
    "f1_0s = f1_score(ytrue_dev_0s, yhat_dev_0s, average=\"macro\")\n",
    "print(f\"[LLM Zero-shot EN] Dev macro-F1: {f1_0s:.4f}\")\n",
    "print(classification_report(ytrue_dev_0s, yhat_dev_0s, digits=4))\n",
    "print(confusion_matrix(ytrue_dev_0s, yhat_dev_0s))\n",
    "\n",
    "eval_en = load_eval(language=\"EN\")\n",
    "cache_eval_0s = OUT_DIR / f\"cache_llm_zeroshot_eval_en_{'wsd' if USE_WSD else 'baseline'}.csv\"\n",
    "yhat_eval_0s = progressive_predict_zero_shot_batched(eval_en, cache_eval_0s, desc=f\"Zero-shot EN (eval, USE_WSD={USE_WSD})\")\n",
    "\n",
    "sub_0s = pd.DataFrame({\n",
    "    \"ID\": eval_en[\"ID\"].astype(str),\n",
    "    \"Language\": eval_en[\"Language\"],\n",
    "    \"Setting\": [\"zero_shot\"] * len(eval_en),\n",
    "    \"Label\": yhat_eval_0s\n",
    "})\n",
    "sub_0s_path = OUT_DIR / f\"eval_submission_en_llm_zeroshot_{'wsd' if USE_WSD else 'baseline'}.csv\"\n",
    "sub_0s.to_csv(sub_0s_path, index=False)\n",
    "print(f\"Wrote {sub_0s_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b929a",
   "metadata": {},
   "source": [
    "## One-shot EN with optional WSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8309f414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating train/dev (EN, oneshot=True) with WSD...\n",
      "One-shot EN (dev, USE_WSD=True) | Resuming with 466 cached / 466 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One-shot EN (dev, USE_WSD=True): 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot EN (dev, USE_WSD=True) | Newly computed: 0 | Cached at start: 466 | Total: 466 | Elapsed: 0.0s | 0.002s/example (new only)\n",
      "[LLM One-shot EN] Dev macro-F1: 0.3836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3802    0.8022    0.5159       182\n",
      "           1     0.5610    0.1620    0.2514       284\n",
      "\n",
      "    accuracy                         0.4120       466\n",
      "   macro avg     0.4706    0.4821    0.3836       466\n",
      "weighted avg     0.4904    0.4120    0.3547       466\n",
      "\n",
      "[[146  36]\n",
      " [238  46]]\n",
      "Annotating eval (EN) with WSD...\n",
      "One-shot EN (eval, USE_WSD=True) | Resuming with 483 cached / 483 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One-shot EN (eval, USE_WSD=True): 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot EN (eval, USE_WSD=True) | Newly computed: 0 | Cached at start: 483 | Total: 483 | Elapsed: 0.0s | 0.001s/example (new only)\n",
      "Wrote outputs_en_llm_wsd/eval_submission_en_llm_oneshot_wsd.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 06 - One-shot EN with optional WSD (self-contained, independent of zero-shot cell)\n",
    "\n",
    "BATCH_GEN = 4   # smaller batch to avoid OOM for long one-shot + WSD prompts\n",
    "\n",
    "from time import perf_counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def _load_cache(cache_path: Path) -> dict:\n",
    "    if cache_path.exists():\n",
    "        df = pd.read_csv(cache_path, dtype={\"ID\": str, \"Label\": int})\n",
    "        return dict(zip(df[\"ID\"].astype(str), df[\"Label\"].astype(int)))\n",
    "    return {}\n",
    "\n",
    "def _append_one(cache_path: Path, rec: tuple):\n",
    "    _id, _lab = rec\n",
    "    header_needed = not cache_path.exists()\n",
    "    with open(cache_path, \"a\") as f:\n",
    "        if header_needed:\n",
    "            f.write(\"ID,Label\\n\")\n",
    "        f.write(f\"{_id},{int(_lab)}\\n\")\n",
    "\n",
    "\n",
    "def build_oneshot_index(train_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    For each MWE, store one positive (label=1) and one negative (label=0) example.\n",
    "    \"\"\"\n",
    "    idx = {}\n",
    "    for _, row in train_df.iterrows():\n",
    "        mwe = row[\"MWE\"]\n",
    "        lab = int(row[\"Label\"])\n",
    "        ctx = pack_context(row.get(\"Previous\",\"\"), row.get(\"Target\",\"\"), row.get(\"Next\",\"\"), mwe)\n",
    "        if mwe not in idx:\n",
    "            idx[mwe] = {0: None, 1: None}\n",
    "        if idx[mwe][lab] is None:\n",
    "            idx[mwe][lab] = {\"context\": ctx}\n",
    "    return idx\n",
    "\n",
    "\n",
    "def pick_global_oneshot_fallback(train_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Pick one global positive and one global negative example as fallback.\n",
    "    \"\"\"\n",
    "    fallback = {0: None, 1: None}\n",
    "    for lab in [0, 1]:\n",
    "        rows = train_df[train_df[\"Label\"] == lab]\n",
    "        if len(rows) > 0:\n",
    "            row = rows.iloc[0]\n",
    "            mwe = row[\"MWE\"]\n",
    "            ctx = pack_context(row.get(\"Previous\",\"\"), row.get(\"Target\",\"\"), row.get(\"Next\",\"\"), mwe)\n",
    "            fallback[lab] = {\"context\": ctx}\n",
    "    # in case one class missing, duplicate the other\n",
    "    if fallback[0] is None and fallback[1] is not None:\n",
    "        fallback[0] = fallback[1]\n",
    "    if fallback[1] is None and fallback[0] is not None:\n",
    "        fallback[1] = fallback[0]\n",
    "    return fallback\n",
    "\n",
    "\n",
    "def make_one_shot_prompt(mwe: str, pos_ctx: str, neg_ctx: str, test_ctx: str) -> str:\n",
    "    return f\"\"\"You are a classifier that decides whether a multiword expression (MWE) is used literally (0) or idiomatically (1).\n",
    "\n",
    "First, see two labeled examples for the same MWE.\n",
    "\n",
    "Example A (idiomatic, label 1):\n",
    "{pos_ctx}\n",
    "\n",
    "Example B (literal, label 0):\n",
    "{neg_ctx}\n",
    "\n",
    "Now classify the following new occurrence of the same MWE:\n",
    "\n",
    "MWE: {mwe}\n",
    "\n",
    "Context:\n",
    "{test_ctx}\n",
    "\n",
    "Answer with a single digit: 0 for literal, 1 for idiomatic.\"\"\"\n",
    "\n",
    "\n",
    "def make_one_shot_prompt_wsd(mwe: str, pos_ctx: str, neg_ctx: str, test_ctx: str, sense_gloss: str) -> str:\n",
    "    sense_gloss = (sense_gloss or \"\").strip()\n",
    "    extra = \"\"\n",
    "    if sense_gloss:\n",
    "        extra = f\"\"\"\\nWe also have a WordNet sense definition for this new occurrence:\n",
    "\"{sense_gloss}\".\"\"\"\n",
    "    return f\"\"\"You are a classifier that decides whether a multiword expression (MWE) is used literally (0) or idiomatically (1).\n",
    "\n",
    "First, see two labeled examples for the same MWE.\n",
    "\n",
    "Example A (idiomatic, label 1):\n",
    "{pos_ctx}\n",
    "\n",
    "Example B (literal, label 0):\n",
    "{neg_ctx}\n",
    "\n",
    "Now classify the following new occurrence of the same MWE:\n",
    "\n",
    "MWE: {mwe}{extra}\n",
    "\n",
    "Context:\n",
    "{test_ctx}\n",
    "\n",
    "Answer with a single digit: 0 for literal, 1 for idiomatic.\"\"\"\n",
    "\n",
    "\n",
    "def progressive_predict_one_shot_batched(df: pd.DataFrame,\n",
    "                                         oneshot_index: dict,\n",
    "                                         global_pool: dict,\n",
    "                                         cache_path: Path,\n",
    "                                         desc: str = \"One-shot EN\") -> list:\n",
    "    df = df.copy()\n",
    "    df[\"ID\"] = df[\"ID\"].astype(str)\n",
    "\n",
    "    preds_map = _load_cache(cache_path)\n",
    "    done = set(preds_map.keys())\n",
    "    todo_idx = [i for i, _id in enumerate(df[\"ID\"]) if _id not in done]\n",
    "\n",
    "    print(f\"{desc} | Resuming with {len(done)} cached / {len(df)} total\")\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    for start in tqdm(range(0, len(todo_idx), BATCH_GEN), desc=desc, leave=True):\n",
    "        batch_rows = todo_idx[start:start+BATCH_GEN]\n",
    "        prompts, ids = [], []\n",
    "        for j in batch_rows:\n",
    "            r = df.iloc[j]\n",
    "            _id = r[\"ID\"]\n",
    "            mwe = r[\"MWE\"]\n",
    "            test_ctx = pack_context(r.get(\"Previous\",\"\"), r.get(\"Target\",\"\"), r.get(\"Next\",\"\"), mwe)\n",
    "\n",
    "            entry = oneshot_index.get(mwe, {0: None, 1: None})\n",
    "            pos_ctx = entry.get(1, {}).get(\"context\") if entry.get(1) else None\n",
    "            neg_ctx = entry.get(0, {}).get(\"context\") if entry.get(0) else None\n",
    "\n",
    "            if pos_ctx is None:\n",
    "                pos_ctx = global_pool[1][\"context\"]\n",
    "            if neg_ctx is None:\n",
    "                neg_ctx = global_pool[0][\"context\"]\n",
    "\n",
    "            if USE_WSD:\n",
    "                gloss = (r.get(\"SenseGloss\", \"\") or \"\").strip()\n",
    "                prompt = make_one_shot_prompt_wsd(mwe, pos_ctx, neg_ctx, test_ctx, gloss)\n",
    "            else:\n",
    "                prompt = make_one_shot_prompt(mwe, pos_ctx, neg_ctx, test_ctx)\n",
    "\n",
    "            prompts.append(prompt)\n",
    "            ids.append(_id)\n",
    "\n",
    "        if not prompts:\n",
    "            continue\n",
    "        labels = classify_prompts_logits(prompts)\n",
    "        for _id, lab in zip(ids, labels):\n",
    "            preds_map[_id] = int(lab)\n",
    "            _append_one(cache_path, (_id, int(lab)))\n",
    "\n",
    "    elapsed = perf_counter() - t0\n",
    "    print(f\"{desc} | Newly computed: {len(todo_idx)} | Cached at start: {len(done)} | Total: {len(df)} | \"\n",
    "          f\"Elapsed: {elapsed:.1f}s | {(elapsed/max(1,len(todo_idx))):.3f}s/example (new only)\")\n",
    "\n",
    "    yhat = [preds_map[str(i)] for i in df[\"ID\"]]\n",
    "    return yhat\n",
    "\n",
    "\n",
    "# ---- Run one-shot EN (dev + eval) ----\n",
    "\n",
    "train_1s_en, dev_1s_en = load_train_dev(language=\"EN\", oneshot=True)\n",
    "oneshot_index = build_oneshot_index(train_1s_en)\n",
    "global_pool = pick_global_oneshot_fallback(train_1s_en)\n",
    "\n",
    "cache_dev_1s = OUT_DIR / f\"cache_llm_oneshot_dev_en_{'wsd' if USE_WSD else 'baseline'}.csv\"\n",
    "yhat_dev_1s = progressive_predict_one_shot_batched(\n",
    "    dev_1s_en, oneshot_index, global_pool, cache_dev_1s,\n",
    "    desc=f\"One-shot EN (dev, USE_WSD={USE_WSD})\"\n",
    ")\n",
    "ytrue_dev_1s = dev_1s_en[\"Label\"].tolist()\n",
    "f1_1s = f1_score(ytrue_dev_1s, yhat_dev_1s, average=\"macro\")\n",
    "print(f\"[LLM One-shot EN] Dev macro-F1: {f1_1s:.4f}\")\n",
    "print(classification_report(ytrue_dev_1s, yhat_dev_1s, digits=4))\n",
    "print(confusion_matrix(ytrue_dev_1s, yhat_dev_1s))\n",
    "\n",
    "eval_en = load_eval(language=\"EN\")\n",
    "cache_eval_1s = OUT_DIR / f\"cache_llm_oneshot_eval_en_{'wsd' if USE_WSD else 'baseline'}.csv\"\n",
    "yhat_eval_1s = progressive_predict_one_shot_batched(\n",
    "    eval_en, oneshot_index, global_pool, cache_eval_1s,\n",
    "    desc=f\"One-shot EN (eval, USE_WSD={USE_WSD})\"\n",
    ")\n",
    "\n",
    "sub_1s = pd.DataFrame({\n",
    "    \"ID\": eval_en[\"ID\"].astype(str),\n",
    "    \"Language\": eval_en[\"Language\"],\n",
    "    \"Setting\": [\"one_shot\"] * len(eval_en),\n",
    "    \"Label\": yhat_eval_1s\n",
    "})\n",
    "sub_1s_path = OUT_DIR / f\"eval_submission_en_llm_oneshot_{'wsd' if USE_WSD else 'baseline'}.csv\"\n",
    "sub_1s.to_csv(sub_1s_path, index=False)\n",
    "print(f\"Wrote {sub_1s_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38281acb",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74920a5a",
   "metadata": {},
   "source": [
    "## Save run metadata for LLM + WSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb7f726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run metadata for LLM + WSD.\n",
      "Output dir: outputs_en_llm_wsd\n"
     ]
    }
   ],
   "source": [
    "# 07 - Save run metadata for LLM + WSD\n",
    "\n",
    "with open(OUT_DIR / f\"run_en_llm_{'wsd' if USE_WSD else 'baseline'}.txt\", \"w\") as f:\n",
    "    f.write(f\"MODEL_NAME={MODEL_NAME}\\n\")\n",
    "    f.write(f\"DEVICE={device.type}\\n\")\n",
    "    f.write(f\"BATCH_GEN={BATCH_GEN}\\n\")\n",
    "    f.write(f\"USE_WSD={USE_WSD}\\n\")\n",
    "    f.write(f\"ZERO_SHOT_DEV_F1={f1_0s:.4f}\\n\")\n",
    "    f.write(f\"ONE_SHOT_DEV_F1={f1_1s:.4f}\\n\")\n",
    "\n",
    "print(\"Saved run metadata for LLM + WSD.\")\n",
    "print(\"Output dir:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
