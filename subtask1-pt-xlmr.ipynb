{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d074b74c",
      "metadata": {
        "id": "d074b74c"
      },
      "source": [
        "## Setup: device, imports, seeds, paths, hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "02e5e7f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02e5e7f6",
        "outputId": "84ad10a6-59d3-4738-9621-70a382b93e44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# 01 - Setup: device, imports, seeds, paths, hyperparams\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "# ---- Single toggle: choose \"cpu\" or \"gpu\"\n",
        "RUN_DEVICE = \"gpu\"   # change to \"cpu\" to force CPU\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "import torch\n",
        "\n",
        "# Resolve requested device against availability\n",
        "if RUN_DEVICE.lower() == \"gpu\" and torch.cuda.is_available():\n",
        "    SELECT_DEVICE = \"cuda\"\n",
        "else:\n",
        "    SELECT_DEVICE = \"cpu\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # hard-disable CUDA if CPU is selected or not available\n",
        "\n",
        "device = torch.device(SELECT_DEVICE)\n",
        "\n",
        "# Determinism-ish settings\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "if device.type == \"cpu\":\n",
        "    torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "# ---- Paths\n",
        "DATA_DIR = Path(\"SemEval_2022_Task2-idiomaticity/SubTaskA\")\n",
        "TRAIN_ONE_SHOT = DATA_DIR / \"Data\" / \"train_one_shot.csv\"\n",
        "TRAIN_ZERO_SHOT = DATA_DIR / \"Data\" / \"train_zero_shot.csv\"\n",
        "DEV = DATA_DIR / \"Data\" / \"dev.csv\"\n",
        "DEV_GOLD = DATA_DIR / \"Data\" / \"dev_gold.csv\"\n",
        "EVAL = DATA_DIR / \"Data\" / \"eval.csv\"\n",
        "\n",
        "OUT_DIR = Path(\"outputs_pt_xlmr\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---- Model & training hyperparams\n",
        "MODEL_NAME = \"xlm-roberta-base\"   # you can try xlm-roberta-large if you have headroom\n",
        "MAX_LEN = 256\n",
        "\n",
        "# zero-shot (full FT)\n",
        "ZS_EPOCHS = 2\n",
        "ZS_LR = 2e-5\n",
        "ZS_WARMUP_RATIO = 0.06\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "# one-shot (head-only FT + focal)\n",
        "OS_EPOCHS = 12\n",
        "OS_LR = 1e-4\n",
        "OS_WARMUP_RATIO = 0.1\n",
        "\n",
        "# batch sizes\n",
        "BATCH_SIZE = 8                     # eval/diagnostics\n",
        "BATCH_SIZE_MICRO = 8               # training micro-batch\n",
        "GRAD_ACCUM_STEPS = 2               # effective batch = micro * accum\n",
        "\n",
        "# pin_memory toggle for CUDA\n",
        "PIN_MEMORY = (device.type == \"cuda\")\n",
        "\n",
        "# ----- Colab VRAM helpers (no-ops on CPU)\n",
        "def cuda_mem():\n",
        "    if device.type == \"cuda\":\n",
        "        alloc = torch.cuda.memory_allocated() / (1024**3)\n",
        "        reserv = torch.cuda.memory_reserved() / (1024**3)\n",
        "        print(f\"CUDA allocated: {alloc:.2f} GiB | reserved: {reserv:.2f} GiB\")\n",
        "\n",
        "def free_vram():\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "        import gc; gc.collect()\n",
        "        print(\"VRAM cleanup done.\")\n",
        "\n",
        "print(f\"Using device: {device.type.upper()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b292cbc",
      "metadata": {
        "id": "3b292cbc"
      },
      "source": [
        "## IO helpers and data preparation for Subtask A (PT only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bcca7eda",
      "metadata": {
        "id": "bcca7eda"
      },
      "outputs": [],
      "source": [
        "# 02 - IO helpers and data prep (PT)\n",
        "\n",
        "def load_any_csv(path: Path) -> pd.DataFrame:\n",
        "    return pd.read_csv(path, sep=None, engine=\"python\", dtype=str)\n",
        "\n",
        "def ensure_label_int(df: pd.DataFrame, col=\"Label\") -> pd.DataFrame:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(int)\n",
        "    return df\n",
        "\n",
        "def prepare_supervised_frame(train_path: Path, dev_path: Path, dev_gold_path: Path, language=\"PT\") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    train_df = load_any_csv(train_path)\n",
        "    dev_df = load_any_csv(dev_path)\n",
        "    gold_df = load_any_csv(dev_gold_path)\n",
        "\n",
        "    train_df.columns = [c.strip() for c in train_df.columns]\n",
        "    dev_df.columns = [c.strip() for c in dev_df.columns]\n",
        "    gold_df.columns = [c.strip() for c in gold_df.columns]\n",
        "\n",
        "    train_df = train_df[train_df[\"Language\"] == language].copy()\n",
        "    dev_df = dev_df[dev_df[\"Language\"] == language].copy()\n",
        "\n",
        "    gold = gold_df[gold_df[\"Language\"] == language][[\"ID\", \"Label\"]].copy()\n",
        "    gold[\"ID\"] = gold[\"ID\"].astype(str); dev_df[\"ID\"] = dev_df[\"ID\"].astype(str)\n",
        "    dev_lab = dev_df.merge(gold, on=\"ID\", how=\"left\")\n",
        "    dev_lab = ensure_label_int(dev_lab, \"Label\")\n",
        "    train_df = ensure_label_int(train_df, \"Label\")\n",
        "    return train_df, dev_lab\n",
        "\n",
        "def prepare_eval_frame(eval_path: Path, language=\"PT\") -> pd.DataFrame:\n",
        "    eval_df = load_any_csv(eval_path)\n",
        "    eval_df.columns = [c.strip() for c in eval_df.columns]\n",
        "    return eval_df[eval_df[\"Language\"] == language].copy()\n",
        "\n",
        "def mark_first_case_insensitive(text: str, needle: str, ltag: str=\"<mwe>\", rtag: str=\"</mwe>\") -> str:\n",
        "    if not isinstance(text, str) or not isinstance(needle, str):\n",
        "        return text\n",
        "    lt, ln = text.lower(), needle.lower()\n",
        "    i = lt.find(ln)\n",
        "    if i == -1:\n",
        "        return text\n",
        "    return text[:i] + ltag + text[i:i+len(needle)] + rtag + text[i+len(needle):]\n",
        "\n",
        "def build_input(prev: str, target: str, nxt: str, mwe: str, sep_token: str) -> str:\n",
        "    prev = \"\" if pd.isna(prev) else prev\n",
        "    nxt = \"\" if pd.isna(nxt) else nxt\n",
        "    target_marked = mark_first_case_insensitive(target, mwe, \"<mwe>\", \"</mwe>\")\n",
        "    return f\"{prev} {sep_token} {target_marked} {sep_token} {nxt}\".strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d4f14d",
      "metadata": {
        "id": "22d4f14d"
      },
      "source": [
        "## Dataset & collate for XLM-R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "81c128fc",
      "metadata": {
        "id": "81c128fc"
      },
      "outputs": [],
      "source": [
        "# 03 - Dataset & collate\n",
        "\n",
        "class IdiomDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_len: int, is_infer: bool=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.is_infer = is_infer\n",
        "        self.sep = tokenizer.sep_token if tokenizer.sep_token is not None else \"</s>\"\n",
        "\n",
        "        self.texts = []\n",
        "        self.labels = []\n",
        "        for _, r in self.df.iterrows():\n",
        "            prev = r.get(\"Previous\", \"\")\n",
        "            target = r.get(\"Target\", \"\")\n",
        "            nxt = r.get(\"Next\", \"\")\n",
        "            mwe = r.get(\"MWE\", \"\")\n",
        "            self.texts.append(build_input(prev, target, nxt, mwe, self.sep))\n",
        "            if not self.is_infer:\n",
        "                self.labels.append(int(r[\"Label\"]))\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\"text\": self.texts[idx]}\n",
        "        if not self.is_infer: item[\"label\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "def collate_fn(batch, tokenizer, max_len: int, is_infer: bool=False):\n",
        "    texts = [b[\"text\"] for b in batch]\n",
        "    enc = tokenizer(texts, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
        "    if not is_infer:\n",
        "        labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n",
        "        return enc, labels\n",
        "    return enc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e24940",
      "metadata": {
        "id": "24e24940"
      },
      "source": [
        "## Model, training, evaluation (fp32 only; gradient accumulation on GPU to keep identical updates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c68a046e",
      "metadata": {
        "id": "c68a046e"
      },
      "outputs": [],
      "source": [
        "# 04 - Model helpers, special tokens, training/eval utils\n",
        "\n",
        "def ensure_mwe_tokens(tokenizer, model=None):\n",
        "    add_list = []\n",
        "    for t in [\"<mwe>\", \"</mwe>\"]:\n",
        "        if t not in tokenizer.get_vocab():\n",
        "            add_list.append(t)\n",
        "    if add_list:\n",
        "        tokenizer.add_special_tokens({\"additional_special_tokens\": add_list})\n",
        "        if model is not None:\n",
        "            model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def build_model_and_tokenizer(model_name: str, move_to_device: bool = False):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=2,\n",
        "        low_cpu_mem_usage=True,\n",
        "        torch_dtype=torch.float32\n",
        "    )\n",
        "    if move_to_device:\n",
        "        model.to(device)\n",
        "    return model, tokenizer\n",
        "\n",
        "def freeze_backbone_roberta(model):\n",
        "    for p in model.roberta.embeddings.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in model.roberta.encoder.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in model.classifier.parameters():\n",
        "        p.requires_grad = True\n",
        "    return model\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def focal_loss(logits, targets, alpha=None, gamma: float = 2.0):\n",
        "    logp = F.log_softmax(logits, dim=-1)\n",
        "    p = torch.exp(logp)\n",
        "    pt = p[range(p.size(0)), targets]\n",
        "    loss = -(1 - pt) ** gamma * logp[range(logp.size(0)), targets]\n",
        "    if alpha is not None:\n",
        "        at = alpha[targets]\n",
        "        loss = at * loss\n",
        "    return loss.mean()\n",
        "\n",
        "def run_epoch(model, loader, tokenizer, optimizer=None, scheduler=None, train_mode: bool=True, accum_steps: int=1):\n",
        "    model.train() if train_mode else model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    total_loss = 0.0\n",
        "    step = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        (enc, labels) = batch\n",
        "        enc = {k: v.to(device, non_blocking=PIN_MEMORY) for k, v in enc.items()}\n",
        "        labels = labels.to(device, non_blocking=PIN_MEMORY)\n",
        "\n",
        "        with torch.set_grad_enabled(train_mode):\n",
        "            out = model(**enc)\n",
        "            logits = out.logits\n",
        "            loss = F.cross_entropy(logits, labels) / accum_steps\n",
        "\n",
        "            if train_mode:\n",
        "                optimizer.zero_grad(set_to_none=True) if (step % accum_steps == 0) else None\n",
        "                loss.backward()\n",
        "                if (step + 1) % accum_steps == 0:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    optimizer.step()\n",
        "                    if scheduler is not None: scheduler.step()\n",
        "\n",
        "        step += 1\n",
        "        total_loss += loss.item() * accum_steps * labels.size(0)\n",
        "        all_preds.extend(torch.argmax(logits, dim=-1).detach().cpu().tolist())\n",
        "        all_labels.extend(labels.detach().cpu().tolist())\n",
        "\n",
        "    avg_loss = total_loss / max(1, len(all_labels))\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    return avg_loss, macro_f1, all_labels, all_preds\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(model, loader, tokenizer):\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    for enc in loader:\n",
        "        enc = {k: v.to(device, non_blocking=PIN_MEMORY) for k, v in enc.items()}\n",
        "        logits = model(**enc).logits\n",
        "        outs.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "    return outs\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_probs_inferloader(model, loader) -> np.ndarray:\n",
        "    model.eval()\n",
        "    probs = []\n",
        "    for enc in loader:\n",
        "        enc = {k: v.to(device, non_blocking=PIN_MEMORY) for k, v in enc.items()}\n",
        "        p = torch.softmax(model(**enc).logits, dim=-1)[:, 1].detach().cpu().numpy()\n",
        "        probs.append(p)\n",
        "    return np.concatenate(probs, axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c8c5f38",
      "metadata": {
        "id": "3c8c5f38"
      },
      "source": [
        "## Data loaders factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "526917e8",
      "metadata": {
        "id": "526917e8"
      },
      "outputs": [],
      "source": [
        "# 05 - DataLoader factories\n",
        "\n",
        "def make_loaders(train_df: pd.DataFrame, dev_df: pd.DataFrame, tokenizer, max_len: int, batch_size_micro: int):\n",
        "    train_ds = IdiomDataset(train_df, tokenizer, max_len, is_infer=False)\n",
        "    dev_ds = IdiomDataset(dev_df, tokenizer, max_len, is_infer=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=batch_size_micro, shuffle=True, pin_memory=PIN_MEMORY,\n",
        "        collate_fn=lambda b: collate_fn(b, tokenizer, max_len, is_infer=False)\n",
        "    )\n",
        "    dev_loader = DataLoader(\n",
        "        dev_ds, batch_size=batch_size_micro, shuffle=False, pin_memory=PIN_MEMORY,\n",
        "        collate_fn=lambda b: collate_fn(b, tokenizer, max_len, is_infer=False)\n",
        "    )\n",
        "    return train_loader, dev_loader\n",
        "\n",
        "def make_infer_loader(df: pd.DataFrame, tokenizer, max_len: int, batch_size: int):\n",
        "    ds = IdiomDataset(df, tokenizer, max_len, is_infer=True)\n",
        "    loader = DataLoader(\n",
        "        ds, batch_size=batch_size, shuffle=False, pin_memory=PIN_MEMORY,\n",
        "        collate_fn=lambda b: collate_fn(b, tokenizer, max_len, is_infer=True)\n",
        "    )\n",
        "    return loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb6bb555",
      "metadata": {
        "id": "eb6bb555"
      },
      "source": [
        "## Zero-shot (PT): train full model, tune threshold, write eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "db4838a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "fb125128f4684facac933dd21f066cf8",
            "f520879d1e684b0b903da81b41ad8eb3",
            "8e4f511155374292a9d6bca119203a17",
            "4f10e256096a41b797537646bd721cd0",
            "057267281b9a4331b2073627bf40dcf6",
            "02d57119b2b341c1970a53130c785e9d",
            "968ed3b7367b488882167bc493fab2cc",
            "ecf9af5d911745bd90c3d29a5874b6a2",
            "9507ae28ce57439482f5efc0663381fa",
            "f0c73bcfff1043e88070540a31910bc3",
            "02c4074339b1482999c715adefba451e",
            "0719750ee9ce4c01b219e8f96b28f832",
            "5eb95edc67384e0a94043b9a18b61ce7",
            "75f6c549f4624beb92fb51d17ea9d511",
            "4819e141204e4f678ed9a61bae3348ac",
            "a19712f7e240430591851eff9c38a9a7",
            "f20fe64e74574dbda320ed1ea6f695b6",
            "c050dc31a09e48beacd88351159f15e4",
            "b364c3548fbb4303af402c8bfe178d20",
            "4c4817532d704751b46b3e5c190631f1",
            "c613f01f9c5b4fe6bced039cda0445bb",
            "66f16e9983ac4fc5b8c49213da9b61ba",
            "01c1f262721442e59cc4263bae6a60f8",
            "dedb59240ace4aa0baefbfa585d8b1a8",
            "0230ed1c9d754e02a070188f555da3ff",
            "f33cf486708e4faca47d36689496a59d",
            "49391e18169542e4b601bf5739b525be",
            "ee0eeb3edaa446a7a0ddb9f73c6020be",
            "e698538760df4629b9da7561d532a543",
            "2e88a7405cfe477da418e0684f7d6aa5",
            "29db5a45eb1245b896e7e13dbed247e6",
            "67bd7a54f84b4554a0185c4ac61b2d5c",
            "8b79b8ac7e284fe09cc5382424fe9e20",
            "a590c0e7c01e402eae81f04de7ff4b1a",
            "d8424cc67436428e95c8847ea5dc60c8",
            "b51fcd9f9a874baaad1d29e6a7b2b01e",
            "d6fd4c18b2d54228a53b55ea3f835003",
            "d5336ff9c3524a9498dddd0b4dc0172b",
            "21de528e6ade40a2a1bdc50e55449aa1",
            "b2647f3c89c346aabe1c89b5ae5c2ac5",
            "b909287009614ce49650ffcd9a0dbdb3",
            "176bc5c7e0e3478eb0f6eb45606a7281",
            "1f35fbe4387341d3a98873c588f71e87",
            "96e9979cb6d04f1badd636a651b46446",
            "d894e9e78da9443b8a18d20df43ee4ec",
            "1414d6f166be4fa6b247938e7386697b",
            "8ef5827a66f143c68c81400987c8541b",
            "4157801981574e17b0126d19cb6cd2b2",
            "80aea2a3b907455a854754bb42dab36f",
            "1838d4b1a4bf47588bc35386b46105d3",
            "b34809827b0c41f6b33dfc8dedc12e2b",
            "abccc87584254c8c8affb67d3fc8a9dc",
            "00fd81109d2d41e1bc905df4f11d9efe",
            "06cf28895a654d8ea705b6157a401d37",
            "85fc313905334ac4be18bbe9d844c6fc"
          ]
        },
        "id": "db4838a7",
        "outputId": "79b6d884-abcf-4ca6-c0e3-9e8a29e282d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA allocated: 0.00 GiB | reserved: 0.00 GiB\n",
            "VRAM cleanup done.\n",
            "CUDA allocated: 0.00 GiB | reserved: 0.00 GiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb125128f4684facac933dd21f066cf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0719750ee9ce4c01b219e8f96b28f832",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01c1f262721442e59cc4263bae6a60f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a590c0e7c01e402eae81f04de7ff4b1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d894e9e78da9443b8a18d20df43ee4ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[zeroshot_pt_xlmr] Epoch 1/2 | Train loss 0.6457 F1 0.3991 | Dev loss 0.7019 F1 0.3607\n",
            "[zeroshot_pt_xlmr] Epoch 2/2 | Train loss 0.6329 F1 0.3991 | Dev loss 0.7379 F1 0.3607\n",
            "[zeroshot_pt_xlmr] Best dev macro-F1: 0.3607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[zeroshot_pt_xlmr] Tuned threshold on dev: th=0.350, macro-F1=0.4821\n",
            "Wrote outputs_pt_xlmr/eval_submission_pt_zeroshot.csv\n"
          ]
        }
      ],
      "source": [
        "# 06 - Zero-shot (PT): train full model, tune threshold, write eval\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    cuda_mem(); free_vram(); cuda_mem()\n",
        "\n",
        "train_0s_df, dev_0s_df = prepare_supervised_frame(TRAIN_ZERO_SHOT, DEV, DEV_GOLD, language=\"PT\")\n",
        "\n",
        "model_zs, tok_zs = build_model_and_tokenizer(MODEL_NAME, move_to_device=False)\n",
        "ensure_mwe_tokens(tok_zs, model_zs)\n",
        "model_zs.to(device)\n",
        "\n",
        "train_loader_0s, dev_loader_0s = make_loaders(train_0s_df, dev_0s_df, tok_zs, MAX_LEN, BATCH_SIZE_MICRO)\n",
        "\n",
        "n_train_0s = len(train_0s_df)\n",
        "updates_per_epoch_0s = math.ceil(n_train_0s / (BATCH_SIZE_MICRO * GRAD_ACCUM_STEPS))\n",
        "total_update_steps_0s = max(1, ZS_EPOCHS * updates_per_epoch_0s)\n",
        "warmup_steps_0s = max(1, int(ZS_WARMUP_RATIO * total_update_steps_0s))\n",
        "\n",
        "optimizer_0s = torch.optim.AdamW(model_zs.parameters(), lr=ZS_LR, weight_decay=WEIGHT_DECAY, foreach=False)\n",
        "scheduler_0s = get_linear_schedule_with_warmup(optimizer_0s, num_warmup_steps=warmup_steps_0s, num_training_steps=total_update_steps_0s)\n",
        "\n",
        "best_f1_zs = -1.0\n",
        "best_dir_zs = OUT_DIR / \"ckpt_zeroshot_pt_xlmr\"\n",
        "best_dir_zs.mkdir(parents=True, exist_ok=True)\n",
        "best_file_zs = best_dir_zs / \"best.pt\"\n",
        "\n",
        "for epoch in range(1, ZS_EPOCHS + 1):\n",
        "    tr_loss, tr_f1, _, _ = run_epoch(model_zs, train_loader_0s, tok_zs, optimizer_0s, scheduler_0s, train_mode=True, accum_steps=GRAD_ACCUM_STEPS)\n",
        "    dv_loss, dv_f1, y_true, y_pred = run_epoch(model_zs, dev_loader_0s, tok_zs, optimizer=None, scheduler=None, train_mode=False, accum_steps=1)\n",
        "    print(f\"[zeroshot_pt_xlmr] Epoch {epoch}/{ZS_EPOCHS} | Train loss {tr_loss:.4f} F1 {tr_f1:.4f} | Dev loss {dv_loss:.4f} F1 {dv_f1:.4f}\")\n",
        "    if dv_f1 > best_f1_zs:\n",
        "        best_f1_zs = dv_f1\n",
        "        torch.save({\"model_state\": model_zs.state_dict(), \"vocab_size\": len(tok_zs)}, best_file_zs)\n",
        "    if device.type == \"cuda\": torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"[zeroshot_pt_xlmr] Best dev macro-F1: {best_f1_zs:.4f}\")\n",
        "\n",
        "# ---- Reload best & tune threshold on dev ----\n",
        "model_zeroshot = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "ensure_mwe_tokens(tok_zs, model_zeroshot)\n",
        "state = torch.load(best_file_zs, map_location=str(device))\n",
        "if \"vocab_size\" in state and model_zeroshot.get_input_embeddings().weight.shape[0] != state[\"vocab_size\"]:\n",
        "    model_zeroshot.resize_token_embeddings(state[\"vocab_size\"])\n",
        "model_zeroshot.load_state_dict(state[\"model_state\"])\n",
        "model_zeroshot.to(device); model_zeroshot.eval()\n",
        "\n",
        "dev_loader_0s_eval = make_infer_loader(dev_0s_df, tok_zs, MAX_LEN, BATCH_SIZE)\n",
        "dev_probs_0s = predict_probs_inferloader(model_zeroshot, dev_loader_0s_eval)\n",
        "dev_true_0s = dev_0s_df[\"Label\"].astype(int).to_numpy()\n",
        "\n",
        "def _tune_threshold(probs, ytrue):\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_th, best_f1 = 0.5, -1.0\n",
        "    for th in grid:\n",
        "        yhat = (probs >= th).astype(int)\n",
        "        f1 = f1_score(ytrue, yhat, average=\"macro\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_th = f1, th\n",
        "    return best_th, best_f1\n",
        "\n",
        "best_th_0s, best_f1_tuned_0s = _tune_threshold(dev_probs_0s, dev_true_0s)\n",
        "print(f\"[zeroshot_pt_xlmr] Tuned threshold on dev: th={best_th_0s:.3f}, macro-F1={best_f1_tuned_0s:.4f}\")\n",
        "\n",
        "# ---- Eval predictions (zero-shot)\n",
        "eval_pt_df = prepare_eval_frame(EVAL, language=\"PT\")\n",
        "eval_loader_0s = make_infer_loader(eval_pt_df, tok_zs, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_with_threshold_inferloader(model, loader, th: float) -> list:\n",
        "    outs = []\n",
        "    for enc in loader:\n",
        "        enc = {k: v.to(device, non_blocking=PIN_MEMORY) for k, v in enc.items()}\n",
        "        p1 = torch.softmax(model(**enc).logits, dim=-1)[:, 1]\n",
        "        outs.extend((p1 >= th).int().cpu().tolist())\n",
        "    return outs\n",
        "\n",
        "eval_preds_0s = predict_with_threshold_inferloader(model_zeroshot, eval_loader_0s, best_th_0s)\n",
        "sub_0s = pd.DataFrame({\n",
        "    \"ID\": eval_pt_df[\"ID\"].astype(str),\n",
        "    \"Language\": eval_pt_df[\"Language\"],\n",
        "    \"Setting\": [\"zero_shot\"] * len(eval_pt_df),\n",
        "    \"Label\": eval_preds_0s\n",
        "})\n",
        "sub_path_0s = OUT_DIR / \"eval_submission_pt_zeroshot.csv\"\n",
        "sub_0s.to_csv(sub_path_0s, index=False)\n",
        "print(f\"Wrote {sub_path_0s}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "I6jz8znIj-gh",
      "metadata": {
        "id": "I6jz8znIj-gh"
      },
      "outputs": [],
      "source": [
        "# GPU/VRAM cleanup helper â€” run this before (re)building models on GPU\n",
        "def free_vram():\n",
        "    import gc, torch\n",
        "    # delete any torch models/tensors we kept around in globals()\n",
        "    for k, v in list(globals().items()):\n",
        "        try:\n",
        "            import torch.nn as nn\n",
        "            if isinstance(v, nn.Module):\n",
        "                del globals()[k]\n",
        "        except Exception:\n",
        "            pass\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            del globals()[k]\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    print(\"VRAM cleanup done.\")\n",
        "\n",
        "# Optional: print quick CUDA memory stats\n",
        "def cuda_mem():\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        a = torch.cuda.memory_allocated() / (1024**3)\n",
        "        r = torch.cuda.memory_reserved() / (1024**3)\n",
        "        print(f\"CUDA allocated: {a:.2f} GiB | reserved: {r:.2f} GiB\")\n",
        "    else:\n",
        "        print(\"CUDA not available.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89a48a68",
      "metadata": {
        "id": "89a48a68"
      },
      "source": [
        "## One-shot (PT) with class-weighted loss (fp32), eval submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b993579f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b993579f",
        "outputId": "b92d1289-ebd4-4acd-ebff-7be7b84d382f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA allocated: 6.24 GiB | reserved: 6.55 GiB\n",
            "VRAM cleanup done.\n",
            "CUDA allocated: 5.21 GiB | reserved: 5.38 GiB\n",
            "[PT one-shot] Train label counts: Counter({0: 28, 1: 25}) | Dev label counts: Counter({0: 154, 1: 119})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[oneshot_pt_frozen_focal] Epoch 1/12 | Train loss 0.2356 F1 0.3592 | Dev F1 0.3036\n",
            "[oneshot_pt_frozen_focal] Epoch 2/12 | Train loss 0.1798 F1 0.5335 | Dev F1 0.4878\n",
            "[oneshot_pt_frozen_focal] Epoch 3/12 | Train loss 0.2296 F1 0.4289 | Dev F1 0.3607\n",
            "[oneshot_pt_frozen_focal] Epoch 4/12 | Train loss 0.2037 F1 0.4395 | Dev F1 0.5487\n",
            "[oneshot_pt_frozen_focal] Epoch 5/12 | Train loss 0.1772 F1 0.5276 | Dev F1 0.3036\n",
            "[oneshot_pt_frozen_focal] Epoch 6/12 | Train loss 0.1659 F1 0.5488 | Dev F1 0.3036\n",
            "[oneshot_pt_frozen_focal] Epoch 7/12 | Train loss 0.1836 F1 0.4172 | Dev F1 0.3018\n",
            "[oneshot_pt_frozen_focal] Epoch 8/12 | Train loss 0.1737 F1 0.6193 | Dev F1 0.4435\n",
            "[oneshot_pt_frozen_focal] Epoch 9/12 | Train loss 0.1865 F1 0.3394 | Dev F1 0.3607\n",
            "[oneshot_pt_frozen_focal] Epoch 10/12 | Train loss 0.1718 F1 0.5662 | Dev F1 0.3607\n",
            "[oneshot_pt_frozen_focal] Epoch 11/12 | Train loss 0.1780 F1 0.3783 | Dev F1 0.3607\n",
            "[oneshot_pt_frozen_focal] Epoch 12/12 | Train loss 0.1687 F1 0.6032 | Dev F1 0.3607\n",
            "[oneshot_pt_frozen_focal] Best dev macro-F1 (argmax): 0.5487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[oneshot_pt_frozen_focal] Dev positive rate (>=0.5): 0.465\n",
            "[oneshot_pt_frozen_focal] Tuned threshold on dev: th=0.500, macro-F1=0.5487\n",
            "Wrote outputs_pt_xlmr/eval_submission_pt_oneshot_weighted.csv\n"
          ]
        }
      ],
      "source": [
        "# 07 - One-shot (PT): frozen backbone + focal loss + threshold tuning\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    cuda_mem(); free_vram(); cuda_mem()\n",
        "\n",
        "train_1s_df, dev_1s_df = prepare_supervised_frame(TRAIN_ONE_SHOT, DEV, DEV_GOLD, language=\"PT\")\n",
        "from collections import Counter\n",
        "cnt_train_1s = Counter(train_1s_df[\"Label\"].astype(int).tolist())\n",
        "cnt_dev_1s = Counter(dev_1s_df[\"Label\"].astype(int).tolist())\n",
        "print(\"[PT one-shot] Train label counts:\", cnt_train_1s, \"| Dev label counts:\", cnt_dev_1s)\n",
        "\n",
        "# alpha vector for focal loss from class weights\n",
        "n0, n1 = cnt_train_1s.get(0, 1), cnt_train_1s.get(1, 1); tot = n0 + n1\n",
        "w0, w1 = tot / (2.0 * n0), tot / (2.0 * n1)\n",
        "alpha_vec = torch.tensor([w0, w1], dtype=torch.float32, device=device)\n",
        "\n",
        "# Build model/tokenizer, add tokens once, freeze encoder\n",
        "model_1s, tok_1s = build_model_and_tokenizer(MODEL_NAME, move_to_device=False)\n",
        "ensure_mwe_tokens(tok_1s, model_1s)\n",
        "freeze_backbone_roberta(model_1s)\n",
        "model_1s.to(device)\n",
        "\n",
        "train_loader_1s, dev_loader_1s = make_loaders(train_1s_df, dev_1s_df, tok_1s, MAX_LEN, BATCH_SIZE_MICRO)\n",
        "\n",
        "n_train_1s = len(train_1s_df)\n",
        "updates_per_epoch_1s = math.ceil(n_train_1s / (BATCH_SIZE_MICRO * GRAD_ACCUM_STEPS))\n",
        "total_update_steps_1s = max(1, OS_EPOCHS * updates_per_epoch_1s)\n",
        "warmup_steps_1s = max(1, int(OS_WARMUP_RATIO * total_update_steps_1s))\n",
        "\n",
        "optim_params = [p for p in model_1s.parameters() if p.requires_grad]\n",
        "optimizer_1s = torch.optim.AdamW(optim_params, lr=OS_LR, weight_decay=WEIGHT_DECAY, foreach=False)\n",
        "scheduler_1s = get_linear_schedule_with_warmup(optimizer_1s, num_warmup_steps=warmup_steps_1s, num_training_steps=total_update_steps_1s)\n",
        "\n",
        "best_f1_1s = -1.0\n",
        "best_dir_1s = OUT_DIR / \"ckpt_oneshot_pt_xlmr_weighted\"\n",
        "best_dir_1s.mkdir(parents=True, exist_ok=True)\n",
        "best_file_1s = best_dir_1s / \"best.pt\"\n",
        "\n",
        "# custom train loop with focal loss\n",
        "step = 0\n",
        "for epoch in range(1, OS_EPOCHS + 1):\n",
        "    model_1s.train()\n",
        "    tr_loss_acc, tr_preds, tr_labels = 0.0, [], []\n",
        "\n",
        "    for batch in train_loader_1s:\n",
        "        enc, labels = batch\n",
        "        enc = {k: v.to(device, non_blocking=PIN_MEMORY) for k, v in enc.items()}\n",
        "        labels = labels.to(device, non_blocking=PIN_MEMORY)\n",
        "\n",
        "        logits = model_1s(**enc).logits\n",
        "        loss = focal_loss(logits, labels, alpha=alpha_vec, gamma=2.0) / GRAD_ACCUM_STEPS\n",
        "        loss.backward()\n",
        "        step += 1\n",
        "\n",
        "        tr_loss_acc += loss.item() * GRAD_ACCUM_STEPS * labels.size(0)\n",
        "        tr_preds.extend(torch.argmax(logits, dim=-1).detach().cpu().tolist())\n",
        "        tr_labels.extend(labels.detach().cpu().tolist())\n",
        "\n",
        "        if step % GRAD_ACCUM_STEPS == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(optim_params, 1.0)\n",
        "            optimizer_1s.step()\n",
        "            scheduler_1s.step()\n",
        "            optimizer_1s.zero_grad(set_to_none=True)\n",
        "\n",
        "    # dev eval (argmax)\n",
        "    _, dv_f1, y_true, y_pred = run_epoch(model_1s, dev_loader_1s, tok_1s, optimizer=None, scheduler=None, train_mode=False, accum_steps=1)\n",
        "    tr_f1 = f1_score(tr_labels, tr_preds, average=\"macro\")\n",
        "    tr_loss = tr_loss_acc / max(1, len(tr_labels))\n",
        "    print(f\"[oneshot_pt_frozen_focal] Epoch {epoch}/{OS_EPOCHS} | Train loss {tr_loss:.4f} F1 {tr_f1:.4f} | Dev F1 {dv_f1:.4f}\")\n",
        "    if dv_f1 > best_f1_1s:\n",
        "        best_f1_1s = dv_f1\n",
        "        torch.save({\"model_state\": model_1s.state_dict(), \"vocab_size\": len(tok_1s)}, best_file_1s)\n",
        "    if device.type == \"cuda\": torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"[oneshot_pt_frozen_focal] Best dev macro-F1 (argmax): {best_f1_1s:.4f}\")\n",
        "\n",
        "# reload & threshold tuning on dev\n",
        "model_1s_eval = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "ensure_mwe_tokens(tok_1s, model_1s_eval)\n",
        "state = torch.load(best_file_1s, map_location=str(device))\n",
        "if \"vocab_size\" in state and model_1s_eval.get_input_embeddings().weight.shape[0] != state[\"vocab_size\"]:\n",
        "    model_1s_eval.resize_token_embeddings(state[\"vocab_size\"])\n",
        "model_1s_eval.load_state_dict(state[\"model_state\"])\n",
        "model_1s_eval.to(device); model_1s_eval.eval()\n",
        "\n",
        "dev_loader_1s_eval = make_infer_loader(dev_1s_df, tok_1s, MAX_LEN, BATCH_SIZE)\n",
        "dev_probs_1s = predict_probs_inferloader(model_1s_eval, dev_loader_1s_eval)\n",
        "dev_true_1s = dev_1s_df[\"Label\"].astype(int).to_numpy()\n",
        "print(f\"[oneshot_pt_frozen_focal] Dev positive rate (>=0.5): {(dev_probs_1s>=0.5).mean():.3f}\")\n",
        "\n",
        "def _tune_threshold(probs, ytrue):\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_th, best_f1 = 0.5, -1.0\n",
        "    for th in grid:\n",
        "        yhat = (probs >= th).astype(int)\n",
        "        f1 = f1_score(ytrue, yhat, average=\"macro\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_th = f1, th\n",
        "    return best_th, best_f1\n",
        "\n",
        "best_th_1s, best_f1_tuned_1s = _tune_threshold(dev_probs_1s, dev_true_1s)\n",
        "print(f\"[oneshot_pt_frozen_focal] Tuned threshold on dev: th={best_th_1s:.3f}, macro-F1={best_f1_tuned_1s:.4f}\")\n",
        "\n",
        "# eval predictions\n",
        "eval_pt_df = prepare_eval_frame(EVAL, language=\"PT\")\n",
        "eval_loader_1s = make_infer_loader(eval_pt_df, tok_1s, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_with_threshold_inferloader(model, loader, th: float) -> list:\n",
        "    outs = []\n",
        "    for enc in loader:\n",
        "        enc = {k: v.to(device, non_blocking=PIN_MEMORY) for k, v in enc.items()}\n",
        "        p1 = torch.softmax(model(**enc).logits, dim=-1)[:, 1]\n",
        "        outs.extend((p1 >= th).int().cpu().tolist())\n",
        "    return outs\n",
        "\n",
        "eval_preds_1s = predict_with_threshold_inferloader(model_1s_eval, eval_loader_1s, best_th_1s)\n",
        "\n",
        "sub_1s = pd.DataFrame({\n",
        "    \"ID\": eval_pt_df[\"ID\"].astype(str),\n",
        "    \"Language\": eval_pt_df[\"Language\"],\n",
        "    \"Setting\": [\"zero_shot\"] * len(eval_pt_df),\n",
        "    \"Label\": eval_preds_1s\n",
        "})\n",
        "sub_path_1s = OUT_DIR / \"eval_submission_pt_oneshot_weighted.csv\"\n",
        "sub_1s.to_csv(sub_path_1s, index=False)\n",
        "print(f\"Wrote {sub_path_1s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf592dd",
      "metadata": {
        "id": "5bf592dd"
      },
      "source": [
        "## Dev diagnostics (confusion/report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a78f5092",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a78f5092",
        "outputId": "de5adee4-1a9c-4b29-b1d4-92f43236419d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[One-shot PT XLM-R (frozen+focal)] Dev macro-F1: 0.5487\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6096    0.5779    0.5933       154\n",
            "           1     0.4882    0.5210    0.5041       119\n",
            "\n",
            "    accuracy                         0.5531       273\n",
            "   macro avg     0.5489    0.5495    0.5487       273\n",
            "weighted avg     0.5567    0.5531    0.5544       273\n",
            "\n",
            "[[89 65]\n",
            " [57 62]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Zero-shot PT XLM-R] Dev macro-F1: 0.3607\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5641    1.0000    0.7213       154\n",
            "           1     0.0000    0.0000    0.0000       119\n",
            "\n",
            "    accuracy                         0.5641       273\n",
            "   macro avg     0.2821    0.5000    0.3607       273\n",
            "weighted avg     0.3182    0.5641    0.4069       273\n",
            "\n",
            "[[154   0]\n",
            " [119   0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# 08 - Dev-set diagnostics: report & confusion matrices\n",
        "\n",
        "def eval_on_dev(best_ckpt_path: Path, tokenizer, dev_df: pd.DataFrame, tag: str):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "    ensure_mwe_tokens(tokenizer, model)\n",
        "    state = torch.load(best_ckpt_path, map_location=str(device))\n",
        "    if \"vocab_size\" in state and model.get_input_embeddings().weight.shape[0] != state[\"vocab_size\"]:\n",
        "        model.resize_token_embeddings(state[\"vocab_size\"])\n",
        "    model.load_state_dict(state[\"model_state\"])\n",
        "    model.to(device); model.eval()\n",
        "\n",
        "    dev_loader = DataLoader(\n",
        "        IdiomDataset(dev_df, tokenizer, MAX_LEN, is_infer=False),\n",
        "        batch_size=BATCH_SIZE, shuffle=False, pin_memory=PIN_MEMORY,\n",
        "        collate_fn=lambda b: collate_fn(b, tokenizer, MAX_LEN, is_infer=False)\n",
        "    )\n",
        "    _, f1, y_true, y_pred = run_epoch(model, dev_loader, tokenizer, optimizer=None, scheduler=None, train_mode=False)\n",
        "    print(f\"[{tag}] Dev macro-F1: {f1:.4f}\")\n",
        "    print(classification_report(y_true, y_pred, digits=4))\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# one-shot diagnostics\n",
        "eval_on_dev(OUT_DIR / \"ckpt_oneshot_pt_xlmr_weighted\" / \"best.pt\", tok_1s, dev_1s_df, \"One-shot PT XLM-R (frozen+focal)\")\n",
        "\n",
        "# zero-shot diagnostics\n",
        "eval_on_dev(OUT_DIR / \"ckpt_zeroshot_pt_xlmr\" / \"best.pt\", tok_zs, dev_0s_df, \"Zero-shot PT XLM-R\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217350f3",
      "metadata": {
        "id": "217350f3"
      },
      "source": [
        "## Save final best checkpoints to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6950641c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6950641c",
        "outputId": "dd228ace-4c2d-4917-8649-403f09688495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved final checkpoints.\n"
          ]
        }
      ],
      "source": [
        "# 09 - Save final checkpoints\n",
        "\n",
        "final_oneshot_dir = OUT_DIR / \"final_oneshot_pt_xlmr\"\n",
        "final_zeroshot_dir = OUT_DIR / \"final_zeroshot_pt_xlmr\"\n",
        "final_oneshot_dir.mkdir(parents=True, exist_ok=True)\n",
        "final_zeroshot_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "torch.save(torch.load(OUT_DIR / \"ckpt_oneshot_pt_xlmr_weighted\" / \"best.pt\", map_location=str(device)),\n",
        "           final_oneshot_dir / \"model.pt\")\n",
        "torch.save(torch.load(OUT_DIR / \"ckpt_zeroshot_pt_xlmr\" / \"best.pt\", map_location=str(device)),\n",
        "           final_zeroshot_dir / \"model.pt\")\n",
        "print(\"Saved final checkpoints.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00fd81109d2d41e1bc905df4f11d9efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01c1f262721442e59cc4263bae6a60f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dedb59240ace4aa0baefbfa585d8b1a8",
              "IPY_MODEL_0230ed1c9d754e02a070188f555da3ff",
              "IPY_MODEL_f33cf486708e4faca47d36689496a59d"
            ],
            "layout": "IPY_MODEL_49391e18169542e4b601bf5739b525be"
          }
        },
        "0230ed1c9d754e02a070188f555da3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e88a7405cfe477da418e0684f7d6aa5",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29db5a45eb1245b896e7e13dbed247e6",
            "value": 5069051
          }
        },
        "02c4074339b1482999c715adefba451e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02d57119b2b341c1970a53130c785e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057267281b9a4331b2073627bf40dcf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cf28895a654d8ea705b6157a401d37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0719750ee9ce4c01b219e8f96b28f832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eb95edc67384e0a94043b9a18b61ce7",
              "IPY_MODEL_75f6c549f4624beb92fb51d17ea9d511",
              "IPY_MODEL_4819e141204e4f678ed9a61bae3348ac"
            ],
            "layout": "IPY_MODEL_a19712f7e240430591851eff9c38a9a7"
          }
        },
        "1414d6f166be4fa6b247938e7386697b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1838d4b1a4bf47588bc35386b46105d3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b34809827b0c41f6b33dfc8dedc12e2b",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "176bc5c7e0e3478eb0f6eb45606a7281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1838d4b1a4bf47588bc35386b46105d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f35fbe4387341d3a98873c588f71e87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21de528e6ade40a2a1bdc50e55449aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29db5a45eb1245b896e7e13dbed247e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e88a7405cfe477da418e0684f7d6aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4157801981574e17b0126d19cb6cd2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06cf28895a654d8ea705b6157a401d37",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_85fc313905334ac4be18bbe9d844c6fc",
            "value": "â€‡1.12G/1.12Gâ€‡[00:15&lt;00:00,â€‡122MB/s]"
          }
        },
        "4819e141204e4f678ed9a61bae3348ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c613f01f9c5b4fe6bced039cda0445bb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_66f16e9983ac4fc5b8c49213da9b61ba",
            "value": "â€‡615/615â€‡[00:00&lt;00:00,â€‡49.8kB/s]"
          }
        },
        "49391e18169542e4b601bf5739b525be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4817532d704751b46b3e5c190631f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f10e256096a41b797537646bd721cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0c73bcfff1043e88070540a31910bc3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_02c4074339b1482999c715adefba451e",
            "value": "â€‡25.0/25.0â€‡[00:00&lt;00:00,â€‡2.59kB/s]"
          }
        },
        "5eb95edc67384e0a94043b9a18b61ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f20fe64e74574dbda320ed1ea6f695b6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c050dc31a09e48beacd88351159f15e4",
            "value": "config.json:â€‡100%"
          }
        },
        "66f16e9983ac4fc5b8c49213da9b61ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67bd7a54f84b4554a0185c4ac61b2d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f6c549f4624beb92fb51d17ea9d511": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b364c3548fbb4303af402c8bfe178d20",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c4817532d704751b46b3e5c190631f1",
            "value": 615
          }
        },
        "80aea2a3b907455a854754bb42dab36f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fc313905334ac4be18bbe9d844c6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b79b8ac7e284fe09cc5382424fe9e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e4f511155374292a9d6bca119203a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecf9af5d911745bd90c3d29a5874b6a2",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9507ae28ce57439482f5efc0663381fa",
            "value": 25
          }
        },
        "8ef5827a66f143c68c81400987c8541b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abccc87584254c8c8affb67d3fc8a9dc",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00fd81109d2d41e1bc905df4f11d9efe",
            "value": 1115567652
          }
        },
        "9507ae28ce57439482f5efc0663381fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "968ed3b7367b488882167bc493fab2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96e9979cb6d04f1badd636a651b46446": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a19712f7e240430591851eff9c38a9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a590c0e7c01e402eae81f04de7ff4b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8424cc67436428e95c8847ea5dc60c8",
              "IPY_MODEL_b51fcd9f9a874baaad1d29e6a7b2b01e",
              "IPY_MODEL_d6fd4c18b2d54228a53b55ea3f835003"
            ],
            "layout": "IPY_MODEL_d5336ff9c3524a9498dddd0b4dc0172b"
          }
        },
        "abccc87584254c8c8affb67d3fc8a9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2647f3c89c346aabe1c89b5ae5c2ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b34809827b0c41f6b33dfc8dedc12e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b364c3548fbb4303af402c8bfe178d20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b51fcd9f9a874baaad1d29e6a7b2b01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b909287009614ce49650ffcd9a0dbdb3",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_176bc5c7e0e3478eb0f6eb45606a7281",
            "value": 9096718
          }
        },
        "b909287009614ce49650ffcd9a0dbdb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c050dc31a09e48beacd88351159f15e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c613f01f9c5b4fe6bced039cda0445bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5336ff9c3524a9498dddd0b4dc0172b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6fd4c18b2d54228a53b55ea3f835003": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f35fbe4387341d3a98873c588f71e87",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_96e9979cb6d04f1badd636a651b46446",
            "value": "â€‡9.10M/9.10Mâ€‡[00:00&lt;00:00,â€‡26.1MB/s]"
          }
        },
        "d8424cc67436428e95c8847ea5dc60c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21de528e6ade40a2a1bdc50e55449aa1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b2647f3c89c346aabe1c89b5ae5c2ac5",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "d894e9e78da9443b8a18d20df43ee4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1414d6f166be4fa6b247938e7386697b",
              "IPY_MODEL_8ef5827a66f143c68c81400987c8541b",
              "IPY_MODEL_4157801981574e17b0126d19cb6cd2b2"
            ],
            "layout": "IPY_MODEL_80aea2a3b907455a854754bb42dab36f"
          }
        },
        "dedb59240ace4aa0baefbfa585d8b1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0eeb3edaa446a7a0ddb9f73c6020be",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e698538760df4629b9da7561d532a543",
            "value": "sentencepiece.bpe.model:â€‡100%"
          }
        },
        "e698538760df4629b9da7561d532a543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecf9af5d911745bd90c3d29a5874b6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0eeb3edaa446a7a0ddb9f73c6020be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c73bcfff1043e88070540a31910bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20fe64e74574dbda320ed1ea6f695b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33cf486708e4faca47d36689496a59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67bd7a54f84b4554a0185c4ac61b2d5c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8b79b8ac7e284fe09cc5382424fe9e20",
            "value": "â€‡5.07M/5.07Mâ€‡[00:00&lt;00:00,â€‡5.82MB/s]"
          }
        },
        "f520879d1e684b0b903da81b41ad8eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02d57119b2b341c1970a53130c785e9d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_968ed3b7367b488882167bc493fab2cc",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "fb125128f4684facac933dd21f066cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f520879d1e684b0b903da81b41ad8eb3",
              "IPY_MODEL_8e4f511155374292a9d6bca119203a17",
              "IPY_MODEL_4f10e256096a41b797537646bd721cd0"
            ],
            "layout": "IPY_MODEL_057267281b9a4331b2073627bf40dcf6"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
